{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from ultralytics.models.yolo.model import YOLO\n",
    "import torch\n",
    "\n",
    "model = YOLO(\"checkpoints/comic-speech-bubble-detector.pt\", task='detect')\n",
    "model.export(format='onnx', imgsz=640)  # creates 'yolov8n.onnx'\n",
    "\n",
    "# results = model.predict(source='GarakutayaManta', save=True, device='cuda:0')  # save plotted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "model = YOLO(\"checkpoints/comic-speech-bubble-detector-640.onnx\", task='detect')\n",
    "\n",
    "results = model.predict(source='dataset/test_folder', device='cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_info = dict()\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    coords = result.boxes.xyxy\n",
    "    sub_dict = dict()\n",
    "    for j, coord in enumerate(coords):\n",
    "        info_dict = dict()\n",
    "        xmin, ymin, xmax, ymax = coord\n",
    "        info_dict['coord'] = (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "        info_dict['img'] = result.orig_img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "        sub_dict[j] = info_dict\n",
    "    result_info['img'] = result.orig_img\n",
    "    result_info[i] = sub_dict\n",
    "\n",
    "file_path = 'nested_dictionary.pkl'\n",
    "\n",
    "# Save the nested dictionary to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(result_info, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'output.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_dict = pickle.load(file)\n",
    "\n",
    "print(\"Loaded dictionary:\", loaded_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "image_path = 'dataset/GarakutayaManta/000.jpg'\n",
    "# img = cv2.imread(image_path)\n",
    "# img = cv2.resize(img, (1024, 1024))\n",
    "# # convert to 3x1024x1024\n",
    "# img = np.moveaxis(img, -1, 0)\n",
    "model(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "a[0].save_crop('', file_name=Path('im'))\n",
    "a[0].save_txt('crop.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "comic = \"AisazuNihaIrarenai\"\n",
    "\n",
    "label = f\"dataset/Manga109_released_2023_12_07/annotations/{comic}.xml\"\n",
    "images = f\"dataset/Manga109_released_2023_12_07/images/{comic}\"\n",
    "outputs = f\"outputs/{images.split('/')[-1]}\"\n",
    "\n",
    "os.makedirs(outputs, exist_ok=True)\n",
    "images_list = sorted(os.listdir(images))\n",
    "\n",
    "with open(label, \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "bs_data = BeautifulSoup(data, 'xml')\n",
    "\n",
    "for page in bs_data.find_all('page'):\n",
    "    page_index = page['index']\n",
    "    print(f\"Page Index: {page_index}\")\n",
    "\n",
    "    image = cv2.imread(os.path.join(images, images_list[int(page_index)]))\n",
    "\n",
    "    # Find all face, frame, and body elements within the page\n",
    "    elements = page.find_all(['text'])\n",
    "    for element in elements:\n",
    "        xmin = element['xmin']\n",
    "        ymin = element['ymin']\n",
    "        xmax = element['xmax']\n",
    "        ymax = element['ymax']\n",
    "        cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "    cv2.imwrite(os.path.join(outputs, images_list[int(page_index)]), image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
